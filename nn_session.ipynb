{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e94ef844-bbb6-42bb-95e4-817818ff19fa",
      "metadata": {
        "id": "e94ef844-bbb6-42bb-95e4-817818ff19fa"
      },
      "source": [
        "# Neural Networks Skills Session\n",
        "*Notebook for my skills session on neural networks on 2024-03-01*\n",
        "\n",
        "The aims for this skills session are to:\n",
        "- Give you an idea of what a neural network actually is\n",
        "- Show you what the caveats are (they aren't actually magic)\n",
        "- Get you training a neural network to emulate simple stellar evolution data\n",
        "\n",
        "\n",
        "Get started with some imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "7b79411b-d1a0-41c9-aecf-606b06571982",
      "metadata": {
        "id": "7b79411b-d1a0-41c9-aecf-606b06571982"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "539a5425-5a1f-4d50-b74a-8675e79b4601",
      "metadata": {
        "id": "539a5425-5a1f-4d50-b74a-8675e79b4601"
      },
      "source": [
        "# 1 Neural network basics\n",
        "Neural networks are a type of machine learning model which learn to reproduce patterns from the data they are trained on.\n",
        "\n",
        "They consist of a series of interconnected ***layers*** which are populated by one or more ***neurons***. Inputs are passed through :\n",
        "\n",
        "***IMAGE OF HORRIBLE FULLY CONNECTED LAYERS HERE***\n",
        "\n",
        "Seeing diagrams like this might be what has stopped you from looking any further into learning how to train your own neural networks, but I promise it really isn't as bad as it looks!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 What are neurons?\n",
        "Each node in the image above is a singe neuron in an example network.\n",
        "\n",
        "Let's take a look at what a neuron looks like for a single-input network:\n",
        "\n",
        "***NEURON IMAGE HERE, SINGLE INPUT***\n",
        "\n",
        "To get an output $y$ from some input $x$, we just apply a linear transformation of the form\n",
        "\\begin{equation}\n",
        "  y = f(wx+b),\n",
        "\\end{equation}\n",
        "where $w$ is a ***weight*** term, $b$ is a ***bias*** term. ($f(\\cdot)$ is the ***activation function***, we'll come back to this later!)\n",
        "\n",
        "A neural network consisting of a single layer, with a single neuron, and a linear activation function (i.e $f(a) = a$) is just optimising a linear fit by tuning the neuron weights and biases.\n",
        "\n",
        "Let's see how this looks:"
      ],
      "metadata": {
        "id": "QIEcfR5aiOlp"
      },
      "id": "QIEcfR5aiOlp"
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_fit(weight, bias):\n",
        "  ##### generate inputs #####\n",
        "  x = np.random.rand(1000)\n",
        "\n",
        "  ##### generate outputs #####\n",
        "  y = weight*x + bias\n",
        "\n",
        "  ##### create tensorflow model #####\n",
        "  tf.keras.backend.clear_session()\n",
        "  linear_model = tf.keras.Sequential()#instantiate model\n",
        "\n",
        "  linear_model.add(tf.keras.Input(1,))#input layer\n",
        "\n",
        "  linear_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\",))#single dense layer, single neuron, linear activation\n",
        "\n",
        "  linear_model.compile(loss='mae')\n",
        "\n",
        "  linear_model.fit(x,y,epochs=50,batch_size=10, verbose=0)\n",
        "\n",
        "  ##### print neuron weights and biases #####\n",
        "  print(\"linear model weight = \" + str(linear_model.layers[0].get_weights()[0]))\n",
        "  print(\"linear model bias = \" + str(linear_model.layers[0].get_weights()[1]))\n",
        "\n",
        "weight= 0.5 #<--- input value here\n",
        "bias = 0.8 #<--- input value here\n",
        "\n",
        "linear_fit(weight, bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYje1SHCrypi",
        "outputId": "247ad182-ddce-46af-8ec5-e962a906a531"
      },
      "id": "TYje1SHCrypi",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear model weight = [[0.5000921]]\n",
            "linear model bias = [0.79909855]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In many cases, we'll have more than one input into our networks ($\\textbf{x}$).\n",
        "\n",
        "Then our single neuron takes this form:\n",
        "\n",
        "***NEURON IMAGE HERE, MANY INPUTS***\n",
        "\n",
        "And our linear transformation just becomes\n",
        "\\begin{equation}\n",
        "  y = f(\\textbf{w} \\cdot \\textbf{x} +b),\n",
        "\\end{equation}\n",
        "where $\\textbf{w}$ contains multiple weights.\n",
        "\n",
        "Let's see how our simple one neuron network copes with multiple inputs:\n"
      ],
      "metadata": {
        "id": "gWZ_V7C1MQKL"
      },
      "id": "gWZ_V7C1MQKL"
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_fit(weights, bias):\n",
        "  ##### generate inputs and outputs #####\n",
        "  dataset_size=1000\n",
        "  inputs={}\n",
        "  output=np.full(dataset_size, bias)\n",
        "\n",
        "  for idx in range(len(weights)):\n",
        "    x = np.random.rand(dataset_size)\n",
        "    inputs[f'x{idx}'] = x\n",
        "    output += weights[idx]*x\n",
        "\n",
        "  ##### create tensorflow model #####\n",
        "  tf.keras.backend.clear_session()\n",
        "  linear_model = tf.keras.Sequential()#instantiate model\n",
        "\n",
        "  linear_model.add(tf.keras.Input(len(weights),))#input layer\n",
        "\n",
        "  linear_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\",))#single dense layer, single neuron, linear activation\n",
        "\n",
        "  linear_model.compile(loss='mae')\n",
        "\n",
        "  linear_model.fit(np.column_stack([inputs[f'x{idx}'] for idx in range(len(weights))]),output,epochs=100,batch_size=10, verbose=0)\n",
        "\n",
        "  ##### print neuron weights and biases #####\n",
        "  print(\"linear model weights = \" + str(linear_model.layers[0].get_weights()[0]))\n",
        "  print(\"linear model bias = \" + str(linear_model.layers[0].get_weights()[1]))\n",
        "\n",
        "weights= [0.5,0.8,-0.4,-0.2] #<--- input values here\n",
        "bias = 0.3 #<--- input value here\n",
        "\n",
        "linear_fit(weights, bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPkovihiCnZx",
        "outputId": "088d96b2-5e77-4df2-e0ef-abbed38d27cc"
      },
      "id": "yPkovihiCnZx",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear model weights = [[ 0.50019723]\n",
            " [ 0.80139035]\n",
            " [-0.3993115 ]\n",
            " [-0.19869879]]\n",
            "linear model bias = [0.30024615]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This looks good so far!\n",
        "\n",
        "Now we know what is happening within each neuron, let's move on to the activation function."
      ],
      "metadata": {
        "id": "xxFRTwARS-iq"
      },
      "id": "xxFRTwARS-iq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Activation functions\n",
        "As I mentioned earlier, the product of the linear equation in the neuron is passed through an activation function before we have\n"
      ],
      "metadata": {
        "id": "gtywYgT1SCfF"
      },
      "id": "gtywYgT1SCfF"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}